{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom glob import glob\nimport matplotlib.pyplot as plt","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import tensorflow as tf\n# tf.__version__","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tf_ver = tf.__version__\n# tf_ver","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tf_ver = tf_ver[:-2]\n# tf_ver","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(type(tf_ver))\n# tf_ver = float(tf_ver)\n# print(type(tf_ver))","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if tf_ver >= 2.12:\n#     !pip install tensorflow==2.8\n# else:\n#     pass","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow==2.9","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ntf.__version__","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_PATH = \"/kaggle/input/camvid/CamVid/\"","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"NO. test imgs \", len(glob(BASE_PATH+\"test/*\")))\nprint(\"NO. test labels \", len(glob(BASE_PATH+\"test_labels/*\")))\nprint(\"NO. train imgs \", len(glob(BASE_PATH+\"train/*\")))\nprint(\"NO. train labels \", len(glob(BASE_PATH+\"train_labels/*\")))\nprint(\"NO. val imgs \", len(glob(BASE_PATH+\"val/*\")))\nprint(\"NO. val labels \", len(glob(BASE_PATH+\"val_labels/*\")))","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = pd.read_csv(BASE_PATH+\"class_dict.csv\")\nn_classes = len(classes)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes.iloc[0][0]","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes_dict = {classes.loc[cl][0]:list(classes.loc[cl][1:]) for cl in classes.index}\nclasses_dict","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_img(img , mask=False):\n    fig ,ax = plt.subplots(figsize=(6,6))\n    if not mask:\n        img = plt.imread(BASE_PATH+img)\n    ax.imshow(img)\n    plt.show()\n    return img","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_img(\"train/0001TP_009210.png\")","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img\nimg = load_img(BASE_PATH + '/train_labels/0001TP_009210_L.png')\nimg\n#img = show_img(\"train_labels/0001TP_009210_L.png\")","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = np.array(img)\nprint(img.shape)\n\nprint(len(classes_dict.values()))","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes_dict.values()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c_st =  []\nfor colour in list(classes_dict.values()):   \n    c_st.append(colour)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c_st[6]","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.equal(c_st[6], c_st[6]))        \nprint(np.equal(c_st[6], c_st[8]))        \nprint(np.equal(c_st[6], c_st[1]))   \nprint('--------------------------------'  )   \nprint(c_st[6], c_st[8], c_st[1]   )    ","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# i was getting this error because of string inside the dict.values() array\n# np.equal(['a', 1,1,1], ['a', 1,2,1])\n# UFuncTypeError: ufunc 'equal' did not contain a loop with signature matching types (<class 'numpy.dtype[str_]'>, <class 'numpy.dtype[str_]'>) -> None","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_name = list( (classes_dict.keys())) \nclass_id = 21\n\ncase_all_class = np.float32(np.equal(c_st[class_id ], img)*1)\ncase_true_class =  np.float32(np.all(np.equal(c_st[class_id ], img), axis = -1)*1)\n\n\nfigsize=(15, 3)\n_, axes = plt.subplots(nrows=1, ncols= 3, figsize=figsize)\n\naxes[0].imshow(img)\naxes[1].imshow(case_all_class )\naxes[2].imshow(case_true_class, cmap='gray')\n\nprint('name of the class:', class_name[class_id ]   )\n\nplt.imshow(case_all_class)\nplt.imshow(case_true_class)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_name = list( (classes_dict.keys())) \nclass_id = 21\n\ncase_all_class = np.float32(np.equal(c_st[class_id ], img)*1)\ncase_true_class =  np.float32(np.all(np.equal(c_st[class_id ], img), axis = -1)*1)\n\n\nfigsize=(15, 3)\n_, axes = plt.subplots(nrows=1, ncols= 3, figsize=figsize)\n\naxes[0].imshow(img)\naxes[1].imshow(case_all_class )\naxes[2].imshow(case_true_class, cmap='gray')\n\nprint('name of the class:', class_name[class_id ]   )\n\nplt.imshow(case_all_class)\nplt.imshow(case_true_class)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adjust_mask(mask, flat=False):\n    \n    semantic_map = []\n    for colour in list(classes_dict.values()):        \n        equality = np.equal(mask, colour)# 256x256x3 with True or False\n        class_map = np.all(equality, axis = -1)# 256x256 If all True, then True, else False\n        semantic_map.append(class_map)# List of 256x256 arrays, map of True for a given found color at the pixel, and False otherwise.\n    semantic_map = np.stack(semantic_map, axis=-1)# 256x256x32 True only at the found color, and all False otherwise.\n    if flat:\n        semantic_map = np.reshape(semantic_map, (-1,256*256))\n\n    return np.float32(semantic_map)# convert to numbers","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_mask = adjust_mask(img)\nprint(new_mask.shape,img.shape)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx2rgb={idx:np.array(rgb) for idx, (cl, rgb) in enumerate(classes_dict.items())}","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx2rgb","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def map_class_to_rgb(p):\n    return idx2rgb[p[0]]","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The purpose is, when you get the (nxmxclass_dim) shaped segmentation map, you need to convert it\n# into an image (nxmx3). Below you do that for new_mask array/map from previous block.\n\nrgb_mask = np.apply_along_axis(map_class_to_rgb, -1, np.expand_dims(np.argmax(new_mask, axis=-1), -1))","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_img(rgb_mask,mask=True)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport os\nimport tensorflow as tf\n#import skimage.io as io\n#import skimage.transform as trans\nimport numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import *\nfrom tensorflow.keras.regularizers import * \n\nfrom tensorflow.keras  import backend as keras","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" \n\ndef dice(y_true, y_pred, smooth=1):\n    \n    intersection = K.sum(y_true * y_pred, axis=[-1])\n    union = K.sum(y_true, axis=[-1]) + K.sum(y_pred, axis=[-1])\n    dicef = K.mean((2. * intersection + smooth)/(union + smooth), axis=-1)\n    return dicef\n\n\ndef IOU(y_true, y_pred, smooth=1):\n\n    intersection = K.sum(y_true * y_pred, axis=[-1])\n    union = K.sum(y_true, axis=[-1]) + K.sum(y_pred, axis=[-1])-intersection\n    iou_scr = K.mean(( intersection + smooth)/(union + smooth), axis=-1)\n    return iou_scr","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unet(n_classes, pretrained_weights = None,input_size = (256,256,3), flat=False, ohe=True):\n    inputs = Input(input_size)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    drop5 = Dropout(0.5)(conv5)\n\n    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n    merge6 = concatenate([drop4,up6], axis = 3)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv1,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    #conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    #conv10 = Conv2D(n_classes, (1,1), activation = 'softmax')(conv9)\n    conv10 = Conv2D(n_classes, (1,1), padding='same')(conv9)\n    if flat:\n      output_layer = Reshape((256*256,n_classes))(conv10)\n    else:\n      output_layer = conv10\n    output_layer = Activation('softmax')(output_layer)\n     \n\n    model = Model(inputs = inputs, outputs = output_layer)\n    Adam =  tf.keras.optimizers.Adam\n    if ohe:\n      model.compile(optimizer = Adam(lr = 1e-4), loss = 'categorical_crossentropy', metrics = ['accuracy',dice, IOU])\n    else:\n      model.compile(optimizer = Adam(lr = 1e-4), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy',dicec])\n    \n    #model.summary()\n\n    if(pretrained_weights):\n        model.load_weights(pretrained_weights)\n\n    return model","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = unet(n_classes)\nmodel.summary()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def custom_seg_model(n_classes, pretrained_weights = None,input_size = (256,256,3), flat=False, ohe=True):\n    inputs = Input(input_size)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    \n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    \n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    \n    pool5 = MaxPooling2D(pool_size=(2, 2))(conv4)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool5)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    \n    pool6 = MaxPooling2D(pool_size=(2, 2))(conv5)\n    conv6 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool6)\n    conv6 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n    \n    conv7 = Conv2D(n_classes, 3, padding = 'same', kernel_initializer = 'he_normal')(conv6)\n    \n    deconv8 = Conv2DTranspose(n_classes, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n    bn8 = BatchNormalization()(deconv8)\n    \n    pool51 = MaxPooling2D(pool_size=(2, 2))(conv4)\n    conv51 = Conv2DTranspose(n_classes, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool51)\n    sum51 = tf.math.add(conv51,bn8)\n    \n    deconv9 = Conv2DTranspose(n_classes, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(sum51))\n    bn9 = BatchNormalization()(deconv9)\n    \n    pool41 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv41 = Conv2DTranspose(n_classes, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool41)\n    sum41 = conv41+bn9\n    \n    deconv10 = Conv2DTranspose(n_classes, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (8,8))(sum41))\n    \n    output_layer = deconv10\n#     if flat:\n#       output_layer = Reshape((256*256,n_classes))(conv10)\n#     else:\n#       output_layer = conv10\n#     output_layer = Activation('softmax')(output_layer)\n     \n\n    model = Model(inputs = inputs, outputs = output_layer)\n    Adam =  tf.keras.optimizers.Adam\n    if ohe:\n      model.compile(optimizer = Adam(lr = 1e-4), loss = 'categorical_crossentropy', metrics = ['accuracy',dice, IOU])\n    else:\n      model.compile(optimizer = Adam(lr = 1e-4), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy',dicec])\n    \n    #model.summary()\n\n    if(pretrained_weights):\n        model.load_weights(pretrained_weights)\n\n    return model","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = custom_seg_model(n_classes)\nmodel.summary()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#config \nview = 0\nbatch_sz = 8\nepochs = 10\n \nvalidation_steps = 32","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_gen_args = dict(rescale=1./255)\n\n# So our usage here is as data loader instead of loading everything in RAM, not data augmentation\nmask_gen_args = dict()\n\nimage_datagen = ImageDataGenerator(**data_gen_args)\nmask_datagen  = ImageDataGenerator(**mask_gen_args) \n# Provide the same seed and keyword arguments to the fit and flow methods\nseed = 1\n#image_datagen.fit(images, augment=True, seed=seed)\n#mask_datagen.fit(masks, augment=True, seed=seed)\n\nimage_generator = image_datagen.flow_from_directory(\n    BASE_PATH,\n    class_mode=None,\n    classes=['train'],\n    seed=seed,\n    batch_size=batch_sz,\n    target_size=(256,256))\nmask_generator = mask_datagen.flow_from_directory(\n    BASE_PATH,\n    classes=['train_labels'],\n    class_mode=None,\n    seed=seed,\n    color_mode='rgb',\n    batch_size=batch_sz,\n    target_size=(256,256))\n\n# combine generators into one which yields image and masks\ntrain_generator = zip(image_generator, mask_generator)\n\nval_image_generator = image_datagen.flow_from_directory(\n    BASE_PATH,\n    class_mode=None,\n    classes=['val'],\n    seed=seed,\n    batch_size=batch_sz,\n    target_size=(256,256))\n\nval_mask_generator = mask_datagen.flow_from_directory(\n    BASE_PATH,\n    classes=['val_labels'],\n    class_mode=None,\n    seed=seed,\n    batch_size=batch_sz,\n    color_mode='rgb',\n    target_size=(256,256))\nval_generator = zip(val_image_generator, val_mask_generator)\n","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_generator_fn():\n    for (img,mask) in train_generator:\n    \n        \n        new_mask = adjust_mask(mask)\n        yield (img,new_mask)    ","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val_generator_fn():\n    for (img,mask) in val_generator:\n        new_mask = adjust_mask(mask)\n        yield (img,new_mask)  ","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_train_samples = len(os.listdir(str(BASE_PATH) + '/train/'))\nn_train_samples","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"by default tf==2.12 was installed but it gave different result for cpu and gpu, then installed tf==2.8 it is promising","metadata":{"editable":false}},{"cell_type":"code","source":"model = custom_seg_model(n_classes)\n# model_checkpoint = ModelCheckpoint('unet_camvid.hdf5', monitor='val_loss',verbose=1, save_best_only=True)\nmodel_checkpoint = ModelCheckpoint('custom_seg_model.hdf5', monitor='val_loss',verbose=1, save_best_only=True)\nmodel.fit_generator(train_generator_fn(),\n                    validation_data=val_generator_fn(),\n                    steps_per_epoch=n_train_samples//batch_sz,\n                    validation_steps=validation_steps,\n                    epochs=epochs,\n                    callbacks=[model_checkpoint])","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_seg(img, gt_mask, shape='normal', gt_mode='sparse'):\n  fig , ax = plt.subplots(1,3,figsize=(10,10))\n  \n  # Img\n  ax[0].imshow(img)\n  ax[0].set_title(\"Orignal Image\")\n  \n  # Predict\n  pred_mask = model.predict(np.expand_dims(img, 0))\n  pred_mask = np.argmax(pred_mask, axis=-1)\n  pred_mask = pred_mask[0]\n  if shape=='flat':\n    pred_mask = np.reshape(pred_mask, (256,256)) # Reshape only if you use the flat model. O.w. you dont need\n  \n  rgb_mask = np.apply_along_axis(map_class_to_rgb, -1, np.expand_dims(pred_mask, -1))\n  \n  # Prediction\n  ax[1].imshow(rgb_mask)\n  ax[1].set_title(\"Predicted Mask\")\n\n              \n  # GT mask\n  if gt_mode == 'ohe':\n    gt_img_ohe = np.argmax(gt_mask, axis=-1)\n    gt_mask = np.apply_along_axis(map_class_to_rgb, -1, np.expand_dims(gt_img_ohe, -1))              \n  \n  ax[2].imshow((gt_mask).astype(np.uint8))\n  ax[2].set_title(\"Ground truth\")","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_generator = image_datagen.flow_from_directory(\n    BASE_PATH,\n    class_mode=None,\n    classes=['test'],\n    seed=seed,\n    batch_size=batch_sz,\n    target_size=(256,256))\n\ntest_mask_generator = mask_datagen.flow_from_directory(\n    BASE_PATH,\n    classes=['test_labels'],\n    class_mode=None,\n    seed=seed,\n    batch_size=batch_sz,\n    color_mode='rgb',\n    target_size=(256,256))\n\ntest_generator = zip(val_image_generator, val_mask_generator)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = next(test_image_generator)[0]\ngt_img = next(test_mask_generator)[0]\nvisualize_seg(img, gt_img, gt_mode='sparse')","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(y_true, y_pred):\n  '''\n  Computes IOU and Dice Score.\n\n  Args:\n    y_true (tensor) - ground truth label map\n    y_pred (tensor) - predicted label map\n  '''\n  \n  class_wise_iou = []\n  class_wise_dice_score = []\n\n  smoothening_factor = 0.00001\n\n  for i in range(32):\n    intersection = np.sum((y_pred == i) * (y_true == i))\n    y_true_area = np.sum((y_true == i))\n    y_pred_area = np.sum((y_pred == i))\n    combined_area = y_true_area + y_pred_area\n    \n    iou = (intersection + smoothening_factor) / (combined_area - intersection + smoothening_factor)\n    class_wise_iou.append(iou)\n    \n    dice_score =  2 * ((intersection + smoothening_factor) / (combined_area + smoothening_factor))\n    class_wise_dice_score.append(dice_score)\n\n    return class_wise_iou, class_wise_dice_score","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_img = model.predict(np.expand_dims(img, 0))[0]\npred_mask = np.argmax(p_img, axis=-1)\nrgb_mask = np.apply_along_axis(map_class_to_rgb, -1, np.expand_dims(pred_mask, -1))\n\n\n\nim_iou, im_dice = compute_metrics(np.uint8(gt_img),np.uint8(rgb_mask))\n\nprint('iou score, dice score',im_iou, im_dice  )","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_img.shape","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_mask.shape","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]}]}